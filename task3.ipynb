{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8b43d81-f3aa-40e1-a25c-92df82a1d7ef",
   "metadata": {},
   "source": [
    "Одной из основных проблем метода Ньютона является то, что он метод 2го порядка, а значит требует вычисления Гессиана, что занимает очень много времени. Одной из оптимизаций может послужить обновление Гессиана лишь раз в несколько итераций, но вычисление обратной матрицы тоже очень затратная операция. Чтобы избежать этих затрат, были изобретены квазиньютоновские методы, они не вычисляют Гессиан на каждой итерации, а лишь приблизительно оценивают вид его обратно матрицы, благодаря чему ассимптотика итерации становится не $O(d^3)$, а $O(d^2)$ где d - размерность функции. Для реализации мы выбрали алгоритм Бройдена — Флетчера — Гольдфарба — Шанно (BFGS). Главной его особенностью является вычисление обратной матрицы Гессианы с помощью рекурентной формулы: $C_{k+1} = (I - r * s * y^T)C_k(I - r * y - s^T) + p * s * s^T$, где \n",
    "$r = \\frac{1}{y^T*s}$, $y = x_{new} - x$, $s = grad(x_{new}) - grad(x)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62078dac-be3a-44b4-9e38-44449b3bfe3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, './lib')\n",
    "from bfgs import BFGS\n",
    "from newton import NewtonCG\n",
    "from lrs import gradient, hessian, constant\n",
    "from function_wrapper import FunctionWrapper\n",
    "from output import pretty_print\n",
    "from graphics_plotter import GraphicsPlotter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "384e8ff9-9efb-4db9-ad38-2744c4c10f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "func = lambda: FunctionWrapper(lambda x: 3 * x[0]**2 + x[1]**2 - x[1] + 2)\n",
    "\n",
    "bounds = [[-10, 15], [-10, 15]]\n",
    "\n",
    "bfgs = BFGS(func(), bounds)\n",
    "newton = NewtonCG(constant(1), func(), bounds)\n",
    "\n",
    "x = [-2, -7]\n",
    "steps = 1000\n",
    "\n",
    "gradient.clear()\n",
    "res1 = bfgs.find_min(x, steps)\n",
    "pretty_print(bfgs, \"BFGS\", res1, gradient)\n",
    "\n",
    "hessian.clear()\n",
    "gradient.clear()\n",
    "res2 = newton.find_min(x, steps)\n",
    "pretty_print(newton, \"NewtonCG\", res2, gradient, hessian)\n",
    "\n",
    "plotter1 = GraphicsPlotter(bfgs)\n",
    "plotter2 = GraphicsPlotter(newton)\n",
    "plotter1.plot()\n",
    "plotter2.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70ba9ba-4bcf-41eb-868a-210a655a13f9",
   "metadata": {},
   "source": [
    "Данный тест показывает, что метод BFGS делает не отстаёт в точности от метода Ньютона, при этом не обращая Гессиан, а значит каждая итерация требует $O(dim^2)$ действий, да, в случае функций 2 переменных, константа такая, что BFGS делает больше операций, но посмотрим как ведёт себя данный метод на других функциях."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234016e9-3f1d-4da9-857b-24f1ff3ec79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "func = lambda: FunctionWrapper(lambda x: 3 * x[0]**2 + x[1]**4 - x[1] + 2)\n",
    "\n",
    "bounds = [[-10, 15], [-10, 15]]\n",
    "\n",
    "bfgs = BFGS(func(), bounds)\n",
    "newton = NewtonCG(constant(1), func(), bounds)\n",
    "\n",
    "x = [-2, -7]\n",
    "steps = 1000\n",
    "\n",
    "gradient.clear()\n",
    "res1 = bfgs.find_min(x, steps)\n",
    "pretty_print(bfgs, \"BFGS\", res1, gradient)\n",
    "\n",
    "hessian.clear()\n",
    "gradient.clear()\n",
    "res2 = newton.find_min(x, steps)\n",
    "pretty_print(newton, \"NewtonCG\", res2, gradient, hessian)\n",
    "\n",
    "plotter1 = GraphicsPlotter(bfgs)\n",
    "plotter2 = GraphicsPlotter(newton)\n",
    "plotter1.plot()\n",
    "plotter2.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c2e1b1c-4d9b-422d-8d27-fd3e417894dd",
   "metadata": {},
   "source": [
    "В данном тесте уже BFGS сделал меньше итераций, чем метод Ньютона, при этом, каждая итерация была в 2 раза быстрее, что уже делает BFGS гораздо эффективнее, при этом абсолютно не уступающим в точности."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b552a6c-212b-4321-9441-18042f8f0ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "func = lambda: FunctionWrapper(lambda x: x[0]**4 + (x[1] - 1)**2 + (x[2] - 2)**2 + (x[3] - 3)**2 + (x[4] - 4)**2)\n",
    "\n",
    "dim = 5\n",
    "\n",
    "bounds = [[-10, 15] for i in range(dim)]\n",
    "\n",
    "bfgs = BFGS(func(), bounds, 1e-3)\n",
    "newton = NewtonCG(constant(1), func(), bounds)\n",
    "\n",
    "x = [-2 for i in range(dim)]\n",
    "steps = 1000\n",
    "\n",
    "gradient.clear()\n",
    "res1 = bfgs.find_min(x, steps)\n",
    "pretty_print(bfgs, \"BFGS\", res1, gradient)\n",
    "\n",
    "hessian.clear()\n",
    "gradient.clear()\n",
    "res2 = newton.find_min(x, steps)\n",
    "pretty_print(newton, \"NewtonCG\", res2, gradient, hessian)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ff5f6c-1d2f-4e46-b926-7dd1d2517419",
   "metadata": {},
   "source": [
    "Ну а этот тест окончательно уничтожает метод Ньютона, чётко доказывая, что BFGS работает гораздо эффективнее и быстрее, т.к. метод Ньтона сделал только $13 * 5^3 = 1 625$ действий, в то время как BFGS сделал только $11 * 5^2=275$ что в более чем 5 раз быстрее. А теперь представим, что размерность нашей функции > 1000, и всё станет окончательно понятно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1d155e-96bb-4aec-9861-74dde6ca5c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gradient_descent import ScipyWrapper\n",
    "\n",
    "func = lambda: FunctionWrapper(lambda x: 3 * (x[0] - 3)**6 + x[1]**4 - x[1] + 2)\n",
    "\n",
    "bounds = [[-10, 15], [-10, 15]]\n",
    "\n",
    "bfgs = BFGS(func(), bounds)\n",
    "scipy = ScipyWrapper(func(), bounds)\n",
    "\n",
    "x = [-2, -7]\n",
    "steps = 1000\n",
    "\n",
    "gradient.clear()\n",
    "res1 = bfgs.find_min(x, steps)\n",
    "pretty_print(bfgs, \"BFGS\", res1, gradient)\n",
    "\n",
    "gradient.clear()\n",
    "res2 = scipy.find_min(\"BFGS\", x, steps)\n",
    "pretty_print(scipy, \"scipy\", res2, gradient)\n",
    "\n",
    "plotter1 = GraphicsPlotter(bfgs)\n",
    "plotter2 = GraphicsPlotter(scipy)\n",
    "plotter1.plot()\n",
    "plotter2.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "752f9c90-5403-4215-a4fb-3ba39abf8708",
   "metadata": {},
   "source": [
    "Данный тест показывает, что в сравнении с библиотечной реализацией наш метод неплохо справился! А значит, мы написали хорошую реализацию."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baccd4ad-1b75-4785-b51b-91da730412d4",
   "metadata": {},
   "source": [
    "**Вывод** Метод Ньютона хороший метод оптимизации, но BFGS буквально его улучшенная версия. Он не проигрывает в точности, однако работает гораздо быстрее и эффективнее засчёт рекурентного подсчёта гессиана. Он отлично подходит для нахождения минимума или максимума на области, на которой один экстремум, и, в отличие от метода Ньютона, имеет ассимтотику $O(dim^2)$, что делает его, пока что, лучшим методом из изученных нами. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3599f9f-4798-42a0-a3e2-80093faf7295",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
